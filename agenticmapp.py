# -*- coding: utf-8 -*-
"""AgenticMApp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1inCIg9OqOxapjAvYeTRMi23REbWwiZSN
"""

# Agentic AI Fraud Detection (Colab Version with SHAP and Rule-Based Explanations)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import roc_auc_score, roc_curve

import xgboost as xgb
import shap
from google.colab import files
from IPython.display import display

# Step 1: Upload CSV
uploaded = files.upload()
df = pd.read_csv(next(iter(uploaded)))

# Step 2: Preprocessing
print("‚úÖ Data Uploaded. Sample:")
display(df.head())

print("\nüîÑ Preprocessing...")

df["AmountBucket"] = pd.cut(df["Amount"], bins=[0, 5000, 20000, np.inf],
                             labels=["Low (<$5k)", "Medium ($5k‚Äì$20k)", "High (>$20k)"])
df["VendorCode"] = df["VendorCategory"].astype("category").cat.codes
df["Prior_Vendor"] = df["PriorFlag"] * df["VendorCode"]
df = pd.get_dummies(df, columns=["AmountBucket"], drop_first=False)

X = df[["Amount", "DayOfMonth", "PriorFlag", "VendorCode", "Prior_Vendor"] +
       [c for c in df.columns if "AmountBucket_" in c]]
y = df["IsFraud"]
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,
                                                    test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Step 3: Train Models
print("\nüöÄ Training Models...")

models = {
    "Logistic Regression": LogisticRegression(max_iter=500),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": xgb.XGBClassifier(use_label_encoder=False, eval_metric="logloss"),
    "Neural Network": MLPClassifier(hidden_layer_sizes=(32, 16), max_iter=100)
}

models["Logistic Regression"].fit(X_train_scaled, y_train)
models["Random Forest"].fit(X_train, y_train)
models["XGBoost"].fit(X_train.values, y_train)
models["Neural Network"].fit(X_train_scaled, y_train)

# Step 4: ROC Curves
print("\nüìä ROC Curve Plot:")
plt.figure(figsize=(10, 6))

for name, model in models.items():
    if name in ["Logistic Regression", "Neural Network"]:
        probs = model.predict_proba(X_test_scaled)[:, 1]
    else:
        probs = model.predict_proba(X_test)[:, 1]

    auc = roc_auc_score(y_test, probs)
    fpr, tpr, _ = roc_curve(y_test, probs)
    plt.plot(fpr, tpr, label=f"{name} (AUC={auc:.3f})")

plt.plot([0, 1], [0, 1], 'k--')
plt.title("ROC Curves")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid(True)
plt.show()

# Step 5: Feature Importance - Random Forest
print("\nüìà Feature Importances - Random Forest")
rf = models["Random Forest"]
importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values()
importances.plot(kind="barh", figsize=(8, 6), title="Random Forest Feature Importances")
plt.tight_layout()
plt.show()

# Step 6: SHAP Explanation
print("\nüîç SHAP Summary Plot (Random Forest)")
explainer = shap.TreeExplainer(rf)
shap_values = explainer.shap_values(X_test)

shap.summary_plot(shap_values[1], X_test, show=True)

# Step 7: Q-Learning Policy Table
print("\nüìò Q-Learning Policy Table")
policy_table = pd.DataFrame([
    [0, "Low (<$5k)", +0.65, -0.15, -0.45],
    [0, "Medium ($5k‚Äì$20k)", +0.30, +0.10, -0.10],
    [0, "High (>$20k)", -0.20, +0.45, +0.80],
    [1, "Low (<$5k)", -0.10, +0.40, +0.50],
    [1, "Medium ($5k‚Äì$20k)", -0.30, +0.55, +0.70],
    [1, "High (>$20k)", -0.60, +0.70, +1.00]
], columns=["PriorFlag", "AmountBucket", "Approve", "Flag", "Reject"])

display(policy_table)

# Step 8: Human-Readable Explanations
print("\nüß† Rule-Based Human Explanations")

def interpret_policy(prior_flag, amount):
    if prior_flag == 0:
        if amount < 5000:
            return f"Low amount ${amount:,.0f}, no prior fraud ‚Üí likely safe."
        elif amount < 20000:
            return f"Moderate amount ${amount:,.0f}, no prior fraud ‚Üí mixed risk."
        else:
            return f"High amount ${amount:,.0f}, no prior fraud ‚Üí consider flagging."
    else:
        if amount < 5000:
            return f"Low amount ${amount:,.0f}, but prior fraud ‚Üí flag it."
        elif amount < 20000:
            return f"Moderate amount ${amount:,.0f} with prior fraud ‚Üí risky."
        else:
            return f"High amount ${amount:,.0f} and prior fraud ‚Üí high fraud risk!"

sample_cases = df.sample(5, random_state=1)[["Amount", "PriorFlag"]].copy()
sample_cases["Explanation"] = sample_cases.apply(
    lambda row: interpret_policy(row["PriorFlag"], row["Amount"]), axis=1)

display(sample_cases)

print("\n‚úÖ Done. Fraud detection and explanation completed.")